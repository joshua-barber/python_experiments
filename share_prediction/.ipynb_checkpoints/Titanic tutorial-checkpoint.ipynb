{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data At First Glance: Who Survived The Titanic, And Why?\n",
    " \n",
    "### 1) Importing the required Python dependencies and datafile. \n",
    "The required packages are as follows:\n",
    "   * Matplot lib - 2D plotting library for visualisation<br/>\n",
    "   * Numpy - Scientific computing package<br/>\n",
    "   * Pandas - Widely used data analysis package<br/>\n",
    "   * Sklearn - Machine learning models and tools<br/>\n",
    "   * Tensorflow - Google's open source machine intelligence/neural-net library<br/>\n",
    "\n",
    "Once these are imported we next use pandas to read in the titanic data excel file.  \n",
    "Lastly we view the top 5 rows and confirm it was imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Block import of all required packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, svm, cross_validation, tree, preprocessing, metrics\n",
    "import sklearn.ensemble as ske\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "\n",
    "#Read in the required excel file using pandas function read_excel(). This is using the form:\n",
    "# read_excel([filename],[sheetname],[input the row label column], [how to treat nulls])\n",
    "titanic_df = pd.read_excel('titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])\n",
    "\n",
    "# Use head() to confirm the data has been imported correctly by outputting the top 5 rows\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2) preliminary analysis using pandas.\n",
    "For reference the column headings have the following meanings  \n",
    "> survival -  Survival (0 = No; 1 = Yes)   \n",
    "class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)  \n",
    "name - Name  \n",
    "sex -  Sex  \n",
    "age - Age  \n",
    "sibsp - Number of Siblings/Spouses Aboard  \n",
    "parch - Number of Parents/Children Aboard  \n",
    "ticket - Ticket Number  \n",
    "fare  -  Passenger Fare  \n",
    "cabin - Cabin  \n",
    "embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)  \n",
    "boat - Lifeboat (if survived)  \n",
    "body - Body number (if did not survive and body was recovered)  \n",
    "\n",
    "Now that we have the data in a dataframe, we can begin performing advanced analysis of the data using powerful single-line Pandas functions.  First let’s examine the overall chance of survival for a Titanic passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819709702062643"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation shows that only 38% of the passengers survived.  Not the best odds.  The reason for this massive loss of life is that the Titanic was only carrying 20 lifeboats, which was not nearly enough for the 1,317 passengers and 885 crew members aboard.  It seems unlikely that all of the passengers would have had equal chances at survival, so we will continue breaking down the data to examine the social dynamics that determined who got a place on a lifeboat and who did not.  \n",
    "Social classes were heavily stratified in the early 20th, and this was especially true on the Titanic where the luxurious 1st class areas were completely off limits to the middle-class passengers of 2nd class, and especially to those who carried a 3rd class “economy price” ticket.  \n",
    "\n",
    "To get a view into the composition of each class, we can group data by class, and view the averages for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619195</td>\n",
       "      <td>39.159918</td>\n",
       "      <td>0.436533</td>\n",
       "      <td>0.365325</td>\n",
       "      <td>87.508992</td>\n",
       "      <td>162.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.429603</td>\n",
       "      <td>29.506705</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>0.368231</td>\n",
       "      <td>21.179196</td>\n",
       "      <td>167.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255289</td>\n",
       "      <td>24.816367</td>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.400564</td>\n",
       "      <td>13.302889</td>\n",
       "      <td>155.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        survived        age     sibsp     parch       fare        body\n",
       "pclass                                                                \n",
       "1       0.619195  39.159918  0.436533  0.365325  87.508992  162.828571\n",
       "2       0.429603  29.506705  0.393502  0.368231  21.179196  167.387097\n",
       "3       0.255289  24.816367  0.568406  0.400564  13.302889  155.818182"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('pclass').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start drawing some interesting insights from this data.  For instance, passengers in 1st class had a 62% chance of survival, compared to a 25.5% chance for those in 3rd class.  Additionally, the lower classes generally consisted of younger people, and the ticket prices for first class were predictably much higher than those for second and third class.  The average ticket price for first class, £87.5, is equivalent to $13,487 in 2016.\n",
    "\n",
    "We can extend our statistical breakdown using the grouping function for both class and sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>female</th>\n",
       "      <td>0.965278</td>\n",
       "      <td>37.037594</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>109.412385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.340782</td>\n",
       "      <td>41.029250</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.279330</td>\n",
       "      <td>69.888385</td>\n",
       "      <td>162.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>female</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>27.499191</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>23.234827</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.146199</td>\n",
       "      <td>30.815401</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>19.904946</td>\n",
       "      <td>171.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>female</th>\n",
       "      <td>0.490741</td>\n",
       "      <td>22.185307</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>15.324250</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.152130</td>\n",
       "      <td>25.962273</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>12.415462</td>\n",
       "      <td>151.854167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived        age     sibsp     parch        fare        body\n",
       "pclass sex                                                                    \n",
       "1      female  0.965278  37.037594  0.555556  0.472222  109.412385         NaN\n",
       "       male    0.340782  41.029250  0.340782  0.279330   69.888385  162.828571\n",
       "2      female  0.886792  27.499191  0.500000  0.650943   23.234827   52.000000\n",
       "       male    0.146199  30.815401  0.327485  0.192982   19.904946  171.233333\n",
       "3      female  0.490741  22.185307  0.791667  0.731481   15.324250  183.000000\n",
       "       male    0.152130  25.962273  0.470588  0.255578   12.415462  151.854167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sex_grouping = titanic_df.groupby(['pclass','sex']).mean()\n",
    "class_sex_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb0ecb54d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAE8CAYAAAA2QYEWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLkkNM8QlqWGGuCQ1zBCXpIYZ4pLUsP8PaAlDE1zJNmkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0ecb54b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_sex_grouping['survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Titanic was sinking, the officers famously prioritized who was allowed in a lifeboat with the strict maritime tradition of evacuating women and children first.  Our statistical results clearly reflect the first part of this policy, as across all classes women were much more likely to survive than the men.  We can also see that the women were younger than the men on average, were more likely to be traveling with family, and paid slightly more for their tickets.\n",
    "\n",
    "The effectiveness of the second part of this “Women and children first” policy can be deduced by breaking down the survival rate by age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb0aeb19208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEtCAYAAAD+y1AoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0aeb4dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_by_age = pd.cut(titanic_df['age'], np.arange(0,90,10))\n",
    "age_grouping = titanic_df.groupby(group_by_age).mean()\n",
    "age_grouping['survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that children were indeed the most likely age group to survive, although this percentage was still tragically below 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Enhancing our analysis with Machine Learning\n",
    "We can draw some fairly straightforward conclusions from this data: Being a woman, being in 1st class, and being a child were all factors that could boost your chances of survival during this disaster. Let’s say we wanted to write a program to predict whether a given passenger would survive the disaster.  This could be done through an elaborate system of nested if-else statements with some sort of weighted scoring system, but such a program would be long, tedious to write, difficult to generalize, and would require extensive fine tuning.    \n",
    "\n",
    "This is where machine learning comes in: we will build a program that learns from the sample data in order to predict whether a given passenger would survive. However before we can feed our dataset into a machine learning algorithm, we have to remove missing values and split it into training and test sets.  \n",
    "\n",
    "If we perform a count of each column, we will see that much of the data on certain fields is missing.  Most machine learning algorithms will have a difficult time handling missing values, so we will need to make sure that each row has a value for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1309\n",
       "survived     1309\n",
       "name         1309\n",
       "sex          1309\n",
       "age          1046\n",
       "sibsp        1309\n",
       "parch        1309\n",
       "ticket       1309\n",
       "fare         1308\n",
       "cabin         295\n",
       "embarked     1307\n",
       "boat          486\n",
       "body          121\n",
       "home.dest     745\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1043\n",
       "survived     1043\n",
       "name         1043\n",
       "sex          1043\n",
       "age          1043\n",
       "sibsp        1043\n",
       "parch        1043\n",
       "ticket       1043\n",
       "fare         1043\n",
       "embarked     1043\n",
       "home.dest    1043\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explaining comment\n",
    "titanic_df = titanic_df.drop(['body','cabin','boat'], axis=1)\n",
    "titanic_df['home.dest'] = titanic_df['home.dest'].fillna('NA')\n",
    "titanic_df = titanic_df.dropna()\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see most of the rows are missing values for “boat” and “cabin”, so we will remove these columns from the data frame.  A large number of rows are also missing the “home.dest” field; here we fill the missing values with “NA”.  A significant number rows are also missing an age value.  We have seen above that age could have a significant effect on survival chances, so we will have to drop all of rows that are missing an age value.  When we run the count command again we can see that all remaining columns now contain the same number of values.\n",
    "\n",
    "Now we need to format the remaining data in a way that our machine learning algorithms will accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_titanic_df(df):\n",
    "    processed_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    processed_df.sex = le.fit_transform(processed_df.sex)\n",
    "    processed_df.embarked = le.fit_transform(processed_df.sex)\n",
    "    processed_df = processed_df.drop(['name','ticket','home.dest'], axis=1)\n",
    "    return processed_df\n",
    "\n",
    "#Calling our newly defined preprocess function\n",
    "processed_df = preprocess_titanic_df(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “sex” and “embarked” fields are both string values that correspond to categories(i.e “Male” and “Female”) so we will run each through a preprocessor.  This preprocessor will convert these strings into integer keys, making it easier for the classification algorithms to find patterns.  For instance, “Male” and “Female” will be converted to 0 and 1 respectively.  The “name”, “ticket”, and “home.dest” columns consist of non-categorical string values, and as such are difficult to use in a classification algorithm, so we will drop them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = processed_df.drop(['survived'], axis=1).values\n",
    "y = processed_df['survived'].values\n",
    "#Training\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we separate the dataset into two arrays, “X” containing all of the values for each row besides “survived”, and “y” containing only the “survived” value for that row.  The classification algorithms will compare the attribute values of “X” to the corresponding values of “y” in order to detect patterns in how different attributes values tend to affect the survival of a passenger.\n",
    "\n",
    "Finally we break the “X” and “y” array into two parts each - a training set and a testing set.  We will feed the training set into the classification algorithm in order to form a trained model.  Once the model is formed, we will use it to classify the testing set, allowing us to determine the accuracy of the model.  Here we have have made a 20/80 split, such that 80% of the dataset will be used for training and 20% will be used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Classification: Machine learning in practice\n",
    "We will start off with a simple decision tree classifier.  A decision tree examines one variable at a time, and splits into one of two branches based on the result of that value, at which point it does the same for the next variable. A fantasic visual explanation of how decision trees work can be found here: http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
    "\n",
    "This is what a trained decision tree for the Titanic dataset looks like, if we set the maximum number of levels to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def visualize_tree(tree, feature_names):\\n    Create tree png using graphviz.\\n\\n    Args\\n    ----\\n    tree -- scikit-learn DecsisionTree.\\n    feature_names -- list of feature names.\\n    with open(\".dot\", \\'w\\') as f:\\n        export_graphviz(tree, out_file=f,\\n                        feature_names=feature_names)\\n\\n    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\\n    try:\\n        subprocess.check_call(command)\\n    except:\\n        exit(\"Could not run dot, ie graphviz, to \"\\n             \"produce visualization\")'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To do: Tweak the below to visualise our own tree\n",
    "\"\"\"def visualize_tree(tree, feature_names):\n",
    "    Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    with open(\".dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree first splits by sex, and then by class, since it has learned during the training phase that these are the two most important features for determining survival.  The dark blue boxes indicate passengers who are likely to survive, and the dark orange boxes represent passengers who are almost certainly doomed.  Interestingly, after splitting by class, the main deciding factor determining the survival of women is the ticket fare that they paid, while the deciding factor for men is their age(with children being much more likely to survive).\n",
    "\n",
    "To create this tree, first we initialize an instance of an untrained decision tree classifier(here we will set the maximum depth of the tree to 10).  Next we “fit” this classifier to our training set, enabling it to learn about how different factors affect the survivability of a passenger. Now that the decision tree is ready, we can “score” it using our test data to determine how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82775119617224879"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explanation\n",
    "clf_dt = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf_dt.fit(X_train,y_train)\n",
    "clf_dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting reading, 0.7703, means that the model correctly predicted the survival of 77% of the test set. Not bad for our first model!\n",
    "\n",
    "If you are being an attentive, skeptical reader(as you should be), you might be thinking that the accuracy of the model could vary somewhat depending on which rows were selected for the training and test sets.  We will get around this problem by using a shuffle validator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8098 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "shuffle_validator = cross_validation.ShuffleSplit(len(X), n_iter=20, test_size=0.2, random_state=0)\n",
    "def test_classifier(clf):\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, cv=shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "#Test classifier output\n",
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shuffle validator applies the same random 20:80 split as before, but this time generates 20 unique permutations of this split.  By passing this shuffle validator as a parameter to the “cross_val_score” function, we can score our classifier against each of the different splits, and compute the average accuracy and standard deviation from the results.\n",
    "\n",
    "The result shows that our decision tree classifier has an overall accuracy of 77.34%, although it can go up to 80% and down to 75% depending on the training/test split.  Using scikit-learn, we can easily test other machine learning algorithms using the exact same syntax.\n",
    "\n",
    "##### Random forest\n",
    "The “Random Forest” classification algorithm will create a multitude of (generally very poor) trees for the dataset using different random subsets of the input variables, and will return whichever prediction was returned by the most trees. This helps to avoid “overfitting”, a problem that occurs when a model is so tightly fitted to arbitrary correlations in the training data that it performs poorly on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7864 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "test_classifier(clf_rf)\n",
    "\n",
    "#ske.export_graphviz(CLF_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient boosting\n",
    "The “Gradient Boosting” classifier will generate many weak, shallow prediction trees, and will combine, or “boost”, them into a strong model.  This model performs very well on our dataset, but has the drawback of being relatively slow and difficult to optimize, as the model construction happens sequentially so cannot be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8129 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting\n",
    "A “Voting” classifier can be used to apply multiple conceptually divergent classification models to the same dataset, and will return the majority vote from all of the classifiers.  For instance, if the gradient boosting classifier predicts that a passenger will not survive, but the decision tree and random forest classifiers predict that they will live, the voting classifier will chose the later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8129 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#Voting / Ensemble?\n",
    "eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])\n",
    "test_classifier(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been a very brief and non-technical overview of each technique, so I encourage you to learn more about the mathematical implementations of all of these algorithms to obtain a deeper understanding of their relative strengths and weaknesses.  Many more classification algorithms are available “out-of-the-box” in scikit-learn and can be explored here: http://scikit-learn.org/stable/modules/ensemble.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Computational Brains - An Introduction To Deep Neural Networks  \n",
    "Neural networks are a rapidly developing paradigm for information processing based loosely on how neurons in the brain processes information.  A neural network consists of multiple layers of node, where each node performs a unit of computation, and passes the result onto the next node.  Multiple nodes can pass inputs to a single node, and vice-versa.\n",
    " \n",
    "The neural network also contains a set of weights, which can be refined over time as the network learns from sample data.  The weights are used to describe and refine the connection strengths between nodes.  For instance, in our Titanic data set, node connections transmitting the passenger sex and class will likely be weighted very heavily, since these are important for determining the survival of a passenger. \n",
    "\n",
    "A “Deep Neural Network” (DNN) is a neural network that works not just by passing data between nodes, but by passing data between layers of nodes.  Each layer of nodes is able to aggregate and recombine the outputs from the previous layer, allowing the network to gradually piece together and make sense of unstructured data(such as an image).  Such networks can also be heavily optimized due to their modular nature, allowing the operations of each node layer to be parallelized en masse across multiple CPUs, and even GPUs.\n",
    "\n",
    "We have barely begun to skim the surface of explaining neural networks, for a more in depth explanation of the inner workings of DNNs, this is a good resource: http://deeplearning4j.org/neuralnet-overview.html  \n",
    "While this awesome tool allows you to visualize and modify an active deep neural network: http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.82889&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false\n",
    "\n",
    "The major advantage of neural networks over traditional machine learning techniques is their ability to find patterns in unstructured data(such as images or natural language).  As such, training a deep neural network on the Titanic dataset is total overkill, but it’s a cool technology to work with so we’re going to do it anyway.\n",
    "\n",
    "An emerging powerhouse in programing neural networks is an open source library from Google called TensorFlow. This library is the foundation for many of the most recent advances in machine learning, such as being used to train computer programs to create unique works of music and visual art.  The syntax for using TensorFlow is somewhat abstract, but there is a wrapper included within the TensorFlow package, called “skflow”, which allows us to build deep neural networks using the now familiar scikit-learn syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpbi6mtyfn\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(7)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1811: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  result_shape.insert(dim, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66028708133971292"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_clf_dnn = skflow.DNNClassifier(hidden_units=[20, 40, 20], n_classes=2)\n",
    "tf_clf_dnn.fit(X_train, y_train, steps=1000, batch_size=256)\n",
    "metrics.accuracy_score(y_test, tf_clf_dnn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have written the code to build a deep neural network classifier. The “hidden units” of the classifier represent the neural layers we described earlier, with the corresponding numbers representing the size of each layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpsfanfv1h\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(7)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\n",
      "WARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.layers.stack instead.\n",
      "WARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\n",
      "WARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.layers.stack instead.\n",
      "WARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8133971291866029"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_model(X, y):\n",
    "    layers = skflow.ops.dnn(X, [30, 40, 20], tf.tanh)\n",
    "    return skflow.models.logistic_regression(layers, y)\n",
    "#Explanation\n",
    "tf_clf_c = skflow.TensorFlowEstimator(model_fn=custom_model, n_classes=4, batch_size=512, steps=1000, learning_rate=0.05)\n",
    "tf_clf_c.fit(X_train, y_train)\n",
    "metrics.accuracy_score(y_test, tf_clf_c.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define our own training model to pass to the TensorFlow estimator function as seen above.  Our defined model is very basic, for more advanced examples of how to work within this syntax see the skflow documentation here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/skflow\n",
    "\n",
    "Despite the increased power and lengthier runtime of these neural network models, you will notice that the accuracy is still about the same as what we achieved using more traditional tree based methods.  The main advantage of neural networks, unsupervised learning of unstructured data, does necessarily lend itself well to our Titanic dataset so this is not too surprising.  \n",
    "\n",
    "I still, however, think that running the passenger data of a 104 year old shipwreck through a cutting edge deep neural network is pretty cool."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
